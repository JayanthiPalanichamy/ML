{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet implementation with MNIST example\n",
    "\n",
    "### The paper is described in https://arxiv.org/abs/1412.6622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data # MNIST data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/vijay/workspace/ml/databases/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/vijay/workspace/ml/databases/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/vijay/workspace/ml/databases/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/vijay/workspace/ml/databases/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "LOGDIR = 'logs/'\n",
    "mnist = input_data.read_data_sets('/home/vijay/workspace/ml/databases/MNIST_data', one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convolve 2d with max_pool\n",
    "\n",
    "def conv2d_maxpool(x_tensor, n_conv_dim, conv_ksize, conv_strides, pool_ksize, pool_strides, scope='conv'):\n",
    "    \n",
    "    in_channels = x_tensor.get_shape().as_list()[3]\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        weight = tf.get_variable('w', [conv_ksize[0], conv_ksize[1],in_channels, n_conv_dim], tf.float32, \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.05))\n",
    "        bias = tf.get_variable('b', [n_conv_dim], tf.float32, \n",
    "                           initializer=tf.constant_initializer(0.0))\n",
    "        \n",
    "        conv = tf.nn.conv2d(x_tensor, \n",
    "                        weight, \n",
    "                        strides=[1, conv_strides[0], conv_strides[1], 1],\n",
    "                        padding = 'SAME')\n",
    "        \n",
    "        conv = tf.nn.bias_add(conv, bias)\n",
    "        conv = tf.nn.relu(conv) \n",
    "        conv_maxpool = tf.nn.max_pool(conv,\n",
    "                                  ksize = [1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                                  strides = [1, pool_strides[0], pool_strides[1], 1],\n",
    "                                  padding = 'SAME')\n",
    "    return conv_maxpool\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    size = x_tensor.get_shape().as_list()\n",
    "    x_tensor = tf.reshape(x_tensor, [-1, size[1]*size[2]*size[3]])\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "# fully connected layer\n",
    "def fc_layer(x_tensor, out_dim, scope='fc'):\n",
    "    \n",
    "    in_dim = x_tensor.get_shape().as_list()[1]\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        w = tf.get_variable('w', [in_dim, out_dim], tf.float32, \n",
    "                            initializer=tf.truncated_normal_initializer(stddev=0.05))\n",
    "        b = tf.get_variable('b', [out_dim], tf.float32, \n",
    "                           initializer=tf.constant_initializer(0.0))\n",
    "        act = tf.matmul(x_tensor, w)+b\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)        \n",
    "        return act\n",
    "# network\n",
    "\n",
    "def network(x, dropout):\n",
    "    \n",
    "    conv = conv2d_maxpool(x, 96, (3, 3), (1, 1), (2, 2), (2, 2), 'conv1')\n",
    "    conv = tf.nn.dropout(conv, dropout)\n",
    "    \n",
    "    flat = flatten(conv)\n",
    "    \n",
    "    fc2 = fc_layer(flat, 1024, 'fc1')\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    fc3 = fc_layer(fc2, 256, 'fc2')\n",
    "    fc3 = tf.nn.relu(fc3)\n",
    "    fc3 = tf.nn.l2_normalize(fc3, 1, 1e-10, name='l2-norm')\n",
    "    return fc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, img_size = mnist.train.images.shape\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholder for inputs\n",
    "images_1 = tf.placeholder(tf.float32, [None, img_size], name='img1')\n",
    "images_2 = tf.placeholder(tf.float32, [None, img_size], name='img2')\n",
    "labels = tf.placeholder(tf.float32, [None, 1], name='labels')\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "margin = 1.0\n",
    "\n",
    "#Convert to images for conv layer\n",
    "im_1 = tf.reshape(images_1, [-1, 28, 28, 1])\n",
    "im_2 = tf.reshape(images_2, [-1, 28, 28, 1])\n",
    "\n",
    "#model\n",
    "with tf.variable_scope('Triplet') as scope:\n",
    "    model1_embed = network(im_1, dropout)\n",
    "    scope.reuse_variables()\n",
    "    model2_embed = network(im_2, dropout)\n",
    "    \n",
    "d2 = tf.reduce_sum(tf.square(tf.subtract(model1_embed, model2_embed)), 1, keep_dims=True)\n",
    "distance = tf.sqrt(d2)\n",
    "C = tf.constant(margin, name='C')\n",
    "neg = tf.multiply(tf.subtract(1.0, labels) , tf.square(tf.maximum(0., tf.subtract(C, distance))))\n",
    "pos = tf.multiply(labels, d2)\n",
    "losses = tf.add(pos, neg)\n",
    "with tf.name_scope('loss')\n",
    "    loss = tf.reduce_mean(losses)\n",
    "with tf.name_scope('train')\n",
    "    optimizer = tf.train.AdamOptimizer(3e-4).minimize(loss)\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "import time\n",
    "import random\n",
    "def compute_accuracy(prediction,labels):\n",
    "    \n",
    "    return np.mean(labels.ravel() == 1*(predict.ravel() < 0.5))\n",
    "\n",
    "def create_pairs(x, class_idx):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n_class = len(class_idx)\n",
    "    n = min([len(class_idx[d]) for d in range(n_class)]) - 1\n",
    "    for d in range(n_class):\n",
    "        for i in range(n):\n",
    "            idx1, idx2 = class_idx[d][i], class_idx[d][i+1]\n",
    "            pairs += [[x[idx1], x[idx2]]]\n",
    "            rd = random.randrange(1, n_class)\n",
    "            dn = (d + rd) % n_class\n",
    "            idx1, idx2 = class_idx[d][i], class_idx[dn][i]\n",
    "            pairs += [[x[idx1], x[idx2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "    \n",
    "def next_batch(s,e,inputs,labels):\n",
    "    input1 = inputs[s:e,0]\n",
    "    input2 = inputs[s:e,1]\n",
    "    y= np.reshape(labels[s:e],(len(range(s,e)),1))\n",
    "    return input1,input2,y\n",
    "    \n",
    "batch_size = 512\n",
    "n_epoch = 30\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#write the summaries\n",
    "writer = tf.summary.FileWriter(LOGDIR+'triplet')\n",
    "writer.add_graph(sess.graph) \n",
    "\n",
    "X_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "#create training/test positive-negative pairs\n",
    "n_classes = 10\n",
    "class_idx = [np.where(y_train == i)[0] for i in range(n_classes)]\n",
    "train_pairs, train_labels = create_pairs(X_train, class_idx)\n",
    "\n",
    "class_idx = [np.where(y_test == i)[0] for i in range(n_classes)]\n",
    "test_pairs, test_labels = create_pairs(X_test, class_idx)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    avg_loss = 0.\n",
    "    avg_acc = 0.\n",
    "    start_time = time.time()\n",
    "    train_batch = int(mnist.train.images.shape[0]/batch_size)\n",
    "    test_batch = int(mnist.test.images.shape[0]/batch_size)\n",
    "    \n",
    "    for step in range(train_batch):\n",
    "\n",
    "        batch_x1, batch_x2, batch_y =next_batch(step*batch_size, (step+1)*batch_size, train_pairs, train_labels)\n",
    "        _, loss_b = sess.run([optimizer, loss], feed_dict={\n",
    "                                            images_1: batch_x1,\n",
    "                                            images_2: batch_x2,\n",
    "                                            labels: batch_y,\n",
    "                                            dropout: 0.5})\n",
    "        avg_loss += loss_b \n",
    "        if ((step % 100) == 0) & (step > 0):\n",
    "            print ('Train step %d: loss %.3f' % (step, avg_loss/(step+1)))\n",
    "    # Validation\n",
    "    if (epoch % 10) == 0:\n",
    "        acc_avg = 0.\n",
    "        loss_avg = 0.\n",
    "        for step in range(test_batch):\n",
    "            y = np.reshape(test_labels,(test_labels.shape[0],1))\n",
    "            batch_x1, batch_x2, batch_y =next_batch(step*batch_size, (step+1)*batch_size, test_pairs, test_labels)\n",
    "            predict, loss_b, summary = sess.run([distance, loss, summ], feed_dict={\n",
    "                                                    images_1: batch_x1,\n",
    "                                                    images_2: batch_x2,\n",
    "                                                    labels: batch_y,\n",
    "                                                    dropout: 1.0})\n",
    "            writer.add_summary(s, i)\n",
    "            acc = compute_accuracy(predict, batch_y)\n",
    "            acc_avg += acc\n",
    "            loss_avg += loss_b\n",
    "        acc_avg /= test_batch\n",
    "        loss_avg /= test_batch\n",
    "        duration = time.time() - start_time\n",
    "        print ('Validation: epoch %d: loss: %.3f accuracy: %.3f, duration: %.3f' % (epoch, loss_avg, acc_avg, duration))\n",
    "    \n",
    "saver.save(sess, os.path.join(LOGDIR, 'triplet.ckpt'))\n",
    "embed = sess.run(model1_embed, feed_dict= {images_1: mnist.test.images, dropout: 1.0})\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display_only = 3000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the embeddings using t-sne\n",
    "http://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "display_only = 3000\n",
    "tsne = TSNE(n_components=2)\n",
    "reduced_dim = tsne.fit_transform(embed[:display_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_scatter(values, cls):\n",
    "    # Create a color-map with a different color for each class.\n",
    "    import matplotlib.cm as cm\n",
    "    cmap = cm.rainbow(np.linspace(0.0, 1.0, n_classes))\n",
    "\n",
    "    # Get the color for each sample.\n",
    "    colors = cmap[cls]\n",
    "\n",
    "    # Extract the x- and y-values.\n",
    "    x = values[:, 0]\n",
    "    y = values[:, 1]\n",
    "\n",
    "    # Plot it.\n",
    "    plt.scatter(x, y, color=colors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_scatter(reduced_dim, mnist.test.labels[:display_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "#http://stackoverflow.com/questions/41258391/tensorboard-embedding-example\n",
    "def generate_embeddings(embed):\n",
    "    sess= tf.InteractiveSession()\n",
    "    \n",
    "    embedding = tf.Variable(embed, trainable=False, name='embedding')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('projector', sess.graph)\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_config = config.embeddings.add()\n",
    "    embedding_config.tensor_name = 'embedding:0'\n",
    "    \n",
    "    with open('projector/metadata.tsv', 'w') as f:\n",
    "        for label in mnist.test.labels:\n",
    "            f.write('{}\\n'.format(label))\n",
    "    embedding_config.metadata_path = 'projector/metadata.tsv'\n",
    "    embedding_config.sprite.image_path = 'sprite_1024.png'\n",
    "    \n",
    "    embedding_config.sprite.single_image_dim.extend([28, 28])\n",
    "    projector.visualize_embeddings(writer, config)\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_embeddings(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,label in enumerate(mnist.test.labels):\n",
    "    print (label )\n",
    "    if i is 10:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
